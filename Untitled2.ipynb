{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lazysimon/NYCDSA_CapstoneProject/blob/master/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMbwv1gj45mN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://mirror.its.dal.ca/apache/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xvf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzivGXH946pY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import UserDefinedFunction, explode, desc\n",
        "from pyspark.sql.types import StringType, ArrayType\n",
        "from pyspark.mllib.recommendation import ALS\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GX5yDMQo3nKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movieDF = pd.read_csv(movie_fname, sep='::', header='infer', skipinitialspace=True,names = [\"MovieId\",\"Movie_Title\",\"Genres\"])\n",
        "movieDF = movieDF.drop('Genres', 1)\n",
        "# movieDF[['movie', 'year']] = movieDF['Movie_Title'].str.split('(',expand=True)\n",
        "# movieDF[['year', 'del']] = movieDF['year'].str.split(')',expand=True)\n",
        "# movieDF = movieDF.drop('del',1)\n",
        "# movieDF=movieDF.drop('Movie_Title',1)\n",
        "ratingDF = pd.read_csv(rating_fname, sep='::', header='infer', skipinitialspace=True,names = [\"UserId\", \"MovieId\", \"Rating\", \"Timestamp\"])\n",
        "ratingDF = ratingDF.drop('Timestamp',1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vwkUOWy4eay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mergeDF = pd.merge(movieDF, ratingDF, on=\"MovieId\",how=\"left\")\n",
        "mergeDF['scaled']=np.sign(ratingDF.Rating - 5) ##definitely wrong. needs rework with sigmoid or sth\n",
        "mergeDF.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L9nkFQs5LW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark import SparkContext\n",
        "# spark config\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"movie recommendation\") \\\n",
        "    .config(\"spark.driver.maxResultSize\", \"96g\") \\\n",
        "    .config(\"spark.driver.memory\", \"96g\") \\\n",
        "    .config(\"spark.executor.memory\", \"8g\") \\\n",
        "    .config(\"spark.master\", \"local[12]\") \\\n",
        "    .getOrCreate()\n",
        "# get spark context\n",
        "sc = spark.sparkContext\n",
        "from pyspark.sql import SQLContext\n",
        "sqlCtx = SQLContext(sc)\n",
        "mergeSQL = sqlCtx.createDataFrame(mergeDF)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9F5K4nN5Nd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mergeSQL.describe().show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}